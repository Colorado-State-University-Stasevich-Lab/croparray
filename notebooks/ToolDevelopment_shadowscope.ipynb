{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CropArray example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook summary \n",
    "\n",
    "\n",
    "- Load a microscope image o video\n",
    "- Tracking spots on the image and generate a pandas dataframe with the spots locations\n",
    "- Creating a croparray with the image and dataframe\n",
    "- Visualization with Napari\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set()  \n",
    "import pathlib # for working with windows paths\n",
    "import sys\n",
    "import cv2\n",
    "current_dir = pathlib.Path().absolute()\n",
    "croparray_dir = current_dir.parents[0].joinpath('croparray')\n",
    "sys.path.append(str(croparray_dir))\n",
    "import crop_array_tools as ca\n",
    "# %matplotlib inline \n",
    "#plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"lines.color\": \"white\",\n",
    "    \"patch.edgecolor\": \"white\",\n",
    "    \"text.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"lightgray\",\n",
    "    \"axes.labelcolor\": \"white\",\n",
    "    \"xtick.color\": \"white\",\n",
    "    \"ytick.color\": \"white\",\n",
    "    \"grid.color\": \"None\",\n",
    "    \"figure.facecolor\": \"black\",\n",
    "    \"figure.edgecolor\": \"black\",\n",
    "    \"savefig.facecolor\": \"black\",\n",
    "    \"savefig.edgecolor\": \"black\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for quantification\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "particle_diameter= 25  # Spot diameter : y,x size of the spot      \n",
    "tracking_channel = 0          # Channel  used for tracking\n",
    "min_trajectory_length = 20    # Minimal number of frames to be consider as a trajectory\n",
    "max_distance_movement = 30 #particle_diameter*2\n",
    "# Visualization. Static image taking a given time point. Plotting the maximum projection in Z for a given channel.\n",
    "selected_channel = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video directory\n",
    "img_file_path = current_dir.parents[0].joinpath('database','shadow_scope','834630658_shadow_scope1-cleantwirler-2.mp4')  \n",
    "# Reading a MP4 file\n",
    "frames = []\n",
    "cap = cv2.VideoCapture(str(img_file_path))\n",
    "ret = True\n",
    "while ret:\n",
    "    ret, img = cap.read() # read one frame from the 'capture' object; img is (H, W, C)\n",
    "    if ret:\n",
    "        frames.append(img)\n",
    "img = np.stack(frames, axis=0) # dimensions (T, H, W, C)  \n",
    "\n",
    "print(\"original image shape = \", img.shape)\n",
    "print(\"Image range:  (\", np.min(img), ',' , np.max(img) ,')' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the video to Croparray format\n",
    "img_croparray = np.expand_dims(img,axis=0) # expanding to include fov\n",
    "img_croparray = np.expand_dims(img_croparray,axis=2) # expanding to  z\n",
    "img_croparray.shape # dimensions MUST be (fov, f , z, y, x, ch)\n",
    "img_croparray.shape\n",
    "print(\"croparray format shape [fov, f , z, y, x, ch] = \", img_croparray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting original image\n",
    "# Just examining one of the images\n",
    "selected_time = 100\n",
    "num_channels = 3\n",
    "fig, ax = plt.subplots(nrows=1, ncols=num_channels,figsize=(20,10))\n",
    "for i in range(0,num_channels):\n",
    "    ax[i].imshow(np.max(img_croparray[0,selected_time,:,:,:,i] ,axis=0),cmap='Greys_r' )\n",
    "    ax[i].grid(False)\n",
    "    ax[i].set_title('Channel_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot detection and tracking\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2D = np.amax(img_croparray[0,:,:,:,:,tracking_channel],axis=1)   #(fov, f , z, y, x, ch)\n",
    "img_2D.shape # ( f, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "list_filtered_img = [gaussian_filter(img_2D[i,...], sigma=5) for i in range(0,img_2D.shape[0])]\n",
    "img_2D_filtered = np.asarray(list_filtered_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting original image\n",
    "# Just examining one of the images\n",
    "selected_time = 100\n",
    "num_channels = 3\n",
    "fig, ax = plt.subplots(nrows=1, ncols=num_channels,figsize=(20,10))\n",
    "for i in range(0,num_channels):\n",
    "    ax[i].imshow(img_2D_filtered[selected_time,...],cmap='Greys_r' )\n",
    "    ax[i].grid(False)\n",
    "    ax[i].set_title('Channel_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_df = ca.tracking_spots(img_2D_filtered,particle_diameter=particle_diameter,max_distance_movement=max_distance_movement,\n",
    "                            min_trajectory_length=min_trajectory_length, num_iterations = 100,show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ca = ca.create_crop_array(img_croparray,spots_df,xy_pad=particle_diameter//2)\n",
    "my_ca.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one of the crops over time to test\n",
    "best_z = ca.best_z_proj(my_ca, ref_ch=0, disk_r=3, roll_n=3)\n",
    "#best_z.where(my_ca.id==5).mean('n').sel(fov=0).plot.imshow(col='t',rgb='ch',col_wrap=10,robust=True,xticks=[],yticks=[],size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create best-z projection using channel 1 (translation) as a reference. taking bestz +/- 1 here (roll_n = 3)\n",
    "best_z = ca.best_z_proj(my_ca, ref_ch=1, disk_r=3, roll_n=3)\n",
    "best_z = my_ca.int.sel(fov=0).max('z')\n",
    "best_z.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the action of montage\n",
    "my_ca_montage= ca.montage(best_z, row = 't', col = 'n')\n",
    "print(my_ca_montage.dims)\n",
    "print(my_ca_montage.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage_val  = my_ca_montage.sel(ch=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(montage_val)\n",
    "plt.xlabel('n', size=10)\n",
    "plt.ylabel('t', size=10)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Napari \n",
    "%gui qt5 \n",
    "import napari\n",
    "from napari.utils import nbscreenshot\n",
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the action of montage [rows= time, columns = spot number]\n",
    "viewer.add_image(my_ca_montage.sel(ch=1), colormap = 'green', name = 'green', blending = 'additive', contrast_limits=[0,my_ca_montage.sel(ch=1).data.max()])\n",
    "viewer.add_image(my_ca_montage.sel(ch=0), colormap = 'red', name = 'red', blending='additive', contrast_limits=[0,my_ca_montage.sel(ch=0).data.max()])\n",
    "viewer.add_image(my_ca_montage.sel(ch=2), colormap = 'blue', name = 'blue', blending='additive', contrast_limits=[0,my_ca_montage.sel(ch=2).data.max()])\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
